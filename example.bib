@article{chen2021equivalence,
  title={On the equivalence between neural network and support vector machine},
  author={Chen, Yilan and Huang, Wei and Nguyen, Lam and Weng, Tsui-Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23478--23490},
  year={2021}
}

@article{burgess1996estimating,
  title={Estimating equivalent kernels For neural networks: A data perturbation approach},
  author={Burgess, A},
  journal={Advances in Neural Information Processing Systems},
  volume={9},
  year={1996}
}

@inproceedings{lin2020gradient,
  title={On gradient descent ascent for nonconvex-concave minimax problems},
  author={Lin, Tianyi and Jin, Chi and Jordan, Michael},
  booktitle={International Conference on Machine Learning},
  pages={6083--6093},
  year={2020},
  organization={PMLR}
}

@misc{neuralode2018,
  doi = {10.48550/ARXIV.1806.07366},
  
  url = {https://arxiv.org/abs/1806.07366},
  
  author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Neural Ordinary Differential Equations},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{bilovs2021neural,
  title={Neural flows: Efficient alternative to neural ODEs},
  author={Bilo{\v{s}}, Marin and Sommer, Johanna and Rangapuram, Syama Sundar and Januschowski, Tim and G{\"u}nnemann, Stephan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={21325--21337},
  year={2021}
}
@inproceedings{NIPS2005_663772ea,
	author = {Bengio, Yoshua and Delalleau, Olivier and Roux, Nicolas},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {Y. Weiss and B. Sch\"{o}lkopf and J. Platt},
	publisher = {MIT Press},
	title = {The Curse of Highly Variable Functions for Local Kernel Machines},
	url = {https://proceedings.neurips.cc/paper/2005/file/663772ea088360f95bac3dc7ffb841be-Paper.pdf},
	volume = {18},
	year = {2005},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper/2005/file/663772ea088360f95bac3dc7ffb841be-Paper.pdf}}

@article{nose1990constant,
  title={Constant-temperature molecular dynamics},
  author={Nose, Shuichi},
  journal={Journal of Physics: Condensed Matter},
  volume={2},
  number={S},
  pages={SA115},
  year={1990},
  publisher={IOP Publishing}
}
@article{scherer2020kernel,
  title={Kernel-based machine learning for efficient simulations of molecular liquids},
  author={Scherer, Christoph and Scheid, Ren{\'e} and Andrienko, Denis and Bereau, Tristan},
  journal={Journal of chemical theory and computation},
  volume={16},
  number={5},
  pages={3194--3204},
  year={2020},
  publisher={ACS Publications}
}
@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}
@article{ilyas2019adversarial,
  title={Adversarial examples are not bugs, they are features},
  author={Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{yousefzadeh2021deep,
  title={Deep learning generalization and the convex hull of training sets},
  author={Yousefzadeh, Roozbeh},
  journal={arXiv preprint arXiv:2101.09849},
  year={2021}
}

@article{gillette2022data,
  title={Data-driven geometric scale detection via Delaunay interpolation},
  author={Gillette, Andrew and Kur, Eugene},
  journal={arXiv preprint arXiv:2203.05685},
  year={2022}
}

@book{hardle2004nonparametric,
  title={Nonparametric and semiparametric models},
  author={H{\"a}rdle, Wolfgang and M{\"u}ller, Marlene and Sperlich, Stefan and Werwatz, Axel and others},
  volume={1},
  year={2004},
  publisher={Springer}
}

@article{Selvaraju_2019,
	doi = {10.1007/s11263-019-01228-7},
  
	url = {https://doi.org/10.1007%2Fs11263-019-01228-7},
  
	year = 2019,
	month = {oct},
  
	publisher = {Springer Science and Business Media {LLC}
},
  
	volume = {128},
  
	number = {2},
  
	pages = {336--359},
  
	author = {Ramprasaath R. Selvaraju and Michael Cogswell and Abhishek Das and Ramakrishna Vedantam and Devi Parikh and Dhruv Batra},
  
	title = {Grad-{CAM}: Visual Explanations from Deep Networks via Gradient-Based Localization},
  
	journal = {International Journal of Computer Vision}
}
@misc{lundberg2017unified,
  doi = {10.48550/ARXIV.1705.07874},
  
  url = {https://arxiv.org/abs/1705.07874},
  
  author = {Lundberg, Scott and Lee, Su-In},
  
  keywords = {Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A Unified Approach to Interpreting Model Predictions},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{simonyan2013deep,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1312.6034},
  year={2013}
}
@article{domingos2020,
  author    = {Pedro Domingos},
  title     = {Every Model Learned by Gradient Descent Is Approximately a Kernel
               Machine},
  journal   = {CoRR},
  volume    = {abs/2012.00152},
  year      = {2020},
  url       = {https://arxiv.org/abs/2012.00152},
  eprinttype = {arXiv},
  eprint    = {2012.00152},
  timestamp = {Fri, 04 Dec 2020 12:07:23 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2012-00152.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{domingos2020every,
  title={Every model learned by gradient descent is approximately a kernel machine},
  author={Domingos, Pedro},
  journal={arXiv preprint arXiv:2012.00152},
  year={2020}
}
@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@article{smola2002support,
  title={Support vector machines, regularization, optimization, and beyond},
  author={Smola, A},
  journal={Learning with Kernels},
  year={2002}
}
@article{cortes2009learning,
  title={Learning non-linear combinations of kernels},
  author={Cortes, Corinna and Mohri, Mehryar and Rostamizadeh, Afshin},
  journal={Advances in neural information processing systems},
  volume={22},
  year={2009}
}
@misc{ghojogh2021,
  doi = {10.48550/ARXIV.2106.08443},
  
  url = {https://arxiv.org/abs/2106.08443},
  
  author = {Ghojogh, Benyamin and Ghodsi, Ali and Karray, Fakhri and Crowley, Mark},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Functional Analysis (math.FA), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {Reproducing Kernel Hilbert Space, Mercer's Theorem, Eigenfunctions, Nyström Method, and Use of Kernels in Machine Learning: Tutorial and Survey},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@book{shawe2004kernel,
  title={Kernel methods for pattern analysis},
  author={Shawe-Taylor, John and Cristianini, Nello and others},
  year={2004},
  publisher={Cambridge university press}
}
@inproceedings{zhao2005extracting,
  title={Extracting relations with integrated information using kernel methods},
  author={Zhao, Shubin and Grishman, Ralph},
  booktitle={Proceedings of the 43rd annual meeting of the association for computational linguistics (acl’05)},
  pages={419--426},
  year={2005}
}
@article{he2020bayesian,
  title={Bayesian deep ensembles via the neural tangent kernel},
  author={He, Bobby and Lakshminarayanan, Balaji and Teh, Yee Whye},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1010--1022},
  year={2020}
}
                  

@article{Poupon2004,
title = "Voronoi and Voronoi-related tessellations in studies of protein structure and interaction",
journal = "Current Opinion in Structural Biology",
volume = "14",
number = "2",
pages = "233 - 241",
year = "2004",
issn = "0959-440X",
doi = "https://doi.org/10.1016/j.sbi.2004.03.010",
url = "http://www.sciencedirect.com/science/article/pii/S0959440X04000442",
author = "Anne Poupon"
}                  
                  

@article {Guo1997,
author = {Guo, Baining and Menon, Jai and Willette, Brian},
title = {Surface Reconstruction Using Alpha Shapes},
journal = {Computer Graphics Forum},
volume = {16},
number = {4},
publisher = {Blackwell Publishers},
issn = {1467-8659},
url = {http://dx.doi.org/10.1111/1467-8659.00178},
doi = {10.1111/1467-8659.00178},
pages = {177--190},
keywords = {Surface topology, alpha shapes, manifolds, surface fitting},
year = {1997},
}

@Article{Maus1984,
author="Maus, Arne",
title="Delaunay triangulation and the convex hull ofn points in expected linear time",
journal="BIT Numerical Mathematics",
year="1984",
month="Jun",
day="01",
volume="24",
number="2",
pages="151--163",
abstract="An algorithm is presented which produces a Delaunay triangulation ofn points in the Euclidean plane in expected linear time. The expected execution time is achieved when the data are (not too far from) uniformly distributed. A modification of the algorithm discussed in the appendix treats most of the non-uniform distributions. The basis of this algorithm is a geographical partitioning of the plane into boxes by the well-known Radix-sort algorithm. This partitioning is also used as a basis for a linear time algorithm for finding the convex hull ofn points in the Euclidean plane.",
issn="1572-9125",
doi="10.1007/BF01937482",
url="https://doi.org/10.1007/BF01937482"
}

@Article{Lee1980,
author="Lee, D. T.
and Schachter, B. J.",
title="Two algorithms for constructing a Delaunay triangulation",
journal="International Journal of Computer {\&} Information Sciences",
year="1980",
month="Jun",
day="01",
volume="9",
number="3",
pages="219--242",
abstract="This paper provides a unified discussion of the Delaunay triangulation. Its geometric properties are reviewed and several applications are discussed. Two algorithms are presented for constructing the triangulation over a planar set ofN points. The first algorithm uses a divide-and-conquer approach. It runs inO(N logN) time, which is asymptotically optimal. The second algorithm is iterative and requiresO(N2) time in the worst case. However, its average case performance is comparable to that of the first algorithm.",
issn="1573-7640",
doi="10.1007/BF00977785",
url="https://doi.org/10.1007/BF00977785"
}

@ARTICLE{Edelsbrunner1983, 
author={H. Edelsbrunner and D. Kirkpatrick and R. Seidel}, 
journal={IEEE Transactions on Information Theory}, 
title={On the shape of a set of points in the plane}, 
year={1983}, 
volume={29}, 
number={4}, 
pages={551-559}, 
keywords={Geometry;Image analysis, shape;Image shape analysis}, 
doi={10.1109/TIT.1983.1056714}, 
ISSN={0018-9448}, 
month={July},}

                  % dynamical clustering paper
@article{Drieme2017,
  author    = {Anne Driemel and
               Francesco Silvestri},
  title     = {Locality-sensitive hashing of curves},
  journal   = {CoRR},
  volume    = {abs/1703.04040},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.04040},
  archivePrefix = {arXiv},
  eprint    = {1703.04040},
  timestamp = {Tue, 18 Jul 2017 10:49:06 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/DriemelS17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{Sankararaman2013,
 author = {Sankararaman, Swaminathan and Agarwal, Pankaj K. and M{\o}lhave, Thomas and Pan, Jiangwei and Boedihardjo, Arnold P.},
 title = {Model-driven Matching and Segmentation of Trajectories},
 booktitle = {Proceedings of the 21st ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems},
 series = {SIGSPATIAL'13},
 year = {2013},
 isbn = {978-1-4503-2521-9},
 location = {Orlando, Florida},
 pages = {234--243},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2525314.2525360},
 doi = {10.1145/2525314.2525360},
 acmid = {2525360},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {GPS trajectories, trajectory matching, trajectory segmentation},
} 


@ARTICLE{Mirzargar2014, 
author={M. Mirzargar and R. T. Whitaker and R. M. Kirby}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={Curve Boxplot: Generalization of Boxplot for Ensembles of Curves}, 
year={2014}, 
volume={20}, 
number={12}, 
pages={2654-2663}, 
keywords={computational geometry;data visualisation;boundary values;boxplot generalization;computational scientists;curve boxplot;curve ensembles;data depth;descriptive statistics;nonparametric method;rendering strategies;simulation science;visualization community;visualization strategies;Computational modeling;Curve fitting;Data visualization;Robustness;Shape analysis;Statistical analysis;Uncertainty visualization;boxplots;data depth;ensemble visualization;functional data;nonparametric statistic;order statistics;parametric curves;0}, 
doi={10.1109/TVCG.2014.2346455}, 
ISSN={1077-2626}, 
month={Dec},}

@article{Raj2017,
title = "Path Boxplots: A Method for Characterizing Uncertainty in Path Ensembles on a Graph",
abstract = "Graphs are powerful and versatile data structures that can be used to represent a wide range of different types of information. In this article, we introduce a method to analyze and then visualize an important class of data described over a graph—namely, ensembles of paths. Analysis of such path ensembles is useful in a variety of applications, in diverse fields such as transportation, computer networks, and molecular dynamics. The proposed method generalizes the concept of band depth to an ensemble of paths on a graph, which provides a center-outward ordering on the paths. This ordering is, in turn, used to construct a generalization of the conventional boxplot or whisker plot, called a path boxplot, which applies to paths on a graph. The utility of path boxplot is demonstrated for several examples of path ensembles including paths defined over computer networks and roads. Supplementary materials for this article are available online.",
keywords = "Data depth, Descriptive statistics, Ensemble, Graph, Paths",
author = "Mukund Raj and Mahsa Mirzargar and Robert Ricci and Kirby, {Robert M.} and Whitaker, {Ross T.}",
year = "2017",
month = "4",
doi = "10.1080/10618600.2016.1209115",
volume = "26",
pages = "243--252",
journal = "Journal of Computational and Graphical Statistics",
issn = "1061-8600",
publisher = "American Statistical Association",
number = "2",
}
                  
@Inbook{Kharrat2008,
author="Kharrat, Ahmed
and Popa, Iulian Sandu
and Zeitouni, Karine
and Faiz, Sami",
nothing="Ruas, Anne
and Gold, Christopher",
title="Clustering Algorithm for Network Constraint Trajectories",
bookTitle="Headway in Spatial Data Handling: 13th International Symposium on Spatial Data Handling",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="631--647",
abstract="Spatial data mining is an active topic in spatial databases. This paper proposes a new clustering method for moving object trajectories databases. It applies specifically to trajectories that only lie on a predefined network. The proposed algorithm (NETSCAN) is inspired from the well-known density based algorithms. However, it takes advantage of the network constraint to estimate the object density. Indeed, NETSCAN first computes dense paths in the network based on the moving object count, then, it clusters the sub-trajectories which are similar to the dense paths. The user can adjust the clustering result by setting a density threshold for the dense paths, and a similarity threshold within the clusters. This paper describes the proposed method. An implementation is reported, along with experimental results that show the effectiveness of our approach and the flexibility allowed by the user parameters.",
isbn="978-3-540-68566-1",
doi="10.1007/978-3-540-68566-1_36",
url="https://doi.org/10.1007/978-3-540-68566-1_36"
}
                  
@article{Zheng2015,
 author = {Zheng, Yu},
 title = {Trajectory Data Mining: An Overview},
 journal = {ACM Trans. Intell. Syst. Technol.},
 issue_date = {May 2015},
 volume = {6},
 number = {3},
 month = may,
 year = {2015},
 issn = {2157-6904},
 pages = {29:1--29:41},
 articleno = {29},
 numpages = {41},
 url = {http://doi.acm.org/10.1145/2743025},
 doi = {10.1145/2743025},
 acmid = {2743025},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Spatiotemporal data mining, trajectory classification, trajectory compression, trajectory data mining, trajectory indexing and retrieval, trajectory outlier detection, trajectory pattern mining, trajectory uncertainty, urban computing},
} 

@article{Shah12017,
author = {Shah, Sohil Atul and Koltun, Vladlen}, 
title = {Robust continuous clustering},
volume = {114}, 
number = {37}, 
pages = {9814-9819}, 
year = {2017}, 
doi = {10.1073/pnas.1700770114}, 
abstract ={Clustering is a fundamental procedure in the analysis of scientific data. It is used ubiquitously across the sciences. Despite decades of research, existing clustering algorithms have limited effectiveness in high dimensions and often require tuning parameters for different domains and datasets. We present a clustering algorithm that achieves high accuracy across multiple domains and scales efficiently to high dimensions and large datasets. The presented algorithm optimizes a smooth continuous objective, which is based on robust statistics and allows heavily mixed clusters to be untangled. The continuous nature of the objective also allows clustering to be integrated as a module in end-to-end feature learning pipelines. We demonstrate this by extending the algorithm to perform joint clustering and dimensionality reduction by efficiently optimizing a continuous global objective. The presented approach is evaluated on large datasets of faces, hand-written digits, objects, newswire articles, sensor readings from the Space Shuttle, and protein expression levels. Our method achieves high accuracy across all datasets, outperforming the best prior algorithm by a factor of 3 in average rank.}, 
URL = {http://www.pnas.org/content/114/37/9814.abstract}, 
eprint = {http://www.pnas.org/content/114/37/9814.full.pdf}, 
journal = {Proceedings of the National Academy of Sciences} 
}

@ARTICLE{Jaromczyk1982, 
author={J. W. Jaromczyk and G. T. Toussaint}, 
journal={Proceedings of the IEEE}, 
title={Relative neighborhood graphs and their relatives}, 
year=1992, 
volume=80, 
number=9, 
pages={1502-1517}, 
keywords={computational geometry;computer vision;pattern recognition;spatial data structures;visual databases;computational morphology;computer vision;databases;neighborhood graphs;pattern classification;spatial analysis;Application software;Bibliographies;Biology computing;Computational geometry;Computer applications;Computer science;Computer vision;Morphology;Pattern analysis;Shape}, 
doi={10.1109/5.163414}, 
ISSN={0018-9219}, 
month={Sep},}

@inproceedings{Chakrabarti2006,
  title={Evolutionary clustering},
  author={Chakrabarti, Deepayan and Kumar, Ravi and Tomkins, Andrew},
  booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining}, 
  pages={554--560},
  year={2006},
  organization={ACM}
}

@inproceedings{Andrade2001,
  title={Good approximations for the relative neighbourhood graph.},
  author={Andrade, Diogo Vieira and de Figueiredo, Luiz Henrique},
  booktitle={CCCG},
  pages={25--28},
  year={2001}
}

@book{greene2003,
  title={Econometric Analysis},
  author={Greene, W.H.},
  isbn={9788177586848},
  url={https://books.google.com/books?id=njAcXDlR5U8C},
  year={2003},
  publisher={Pearson Education}
}
                  
@article{mcfadden1973,
  title={Conditional logit analysis of qualitative choice behavior},
  author={McFadden, Daniel and others},
  year={1973},
  journal={Frontiers in Econometrics},
  publisher={Institute of Urban and Regional Development, University of California}
}

@phdthesis{novelli2015,
  title={Detection and Measurement of Sales Cannibalization in Information Technology Markets},
  author={Novelli, Francesco},
  year={2015},
  school={Technische Universit{\"a}t}
}

@article{draganska2004,
  title={A likelihood approach to estimating market equilibrium models},
  author={Draganska, Michaela and Jain, Dipak},
  journal={Management Science},
  volume={50},
  number={5},
  pages={605--616},
  year={2004},
  publisher={INFORMS}
}

@MISC{shriver2015,
  title={A Structural Model of Channel Choice with Implications for Retail Entry},
  author={Shriver, Scott and Bollinger, Bryan},
  year=2015
}

@article{fisher2009,
  title={An algorithm and demand estimation procedure for retail assortment optimization},
  author={Fisher, Marshall L and Vaidyanathan, Ramnath},
  journal={Philadelphia: The Wharton School},
  year={2009}
}

@article{liu1990,
  title={On a notion of data depth based on random simplices},
  author={Liu, Regina Y and others},
  journal={The Annals of Statistics},
  volume={18},
  number={1},
  pages={405--414},
  year={1990},
  publisher={Institute of Mathematical Statistics}
}

@article{lopez2009,
  title={On the concept of depth for functional data},
  author={L{\'o}pez-Pintado, Sara and Romo, Juan},
  journal={Journal of the American Statistical Association},
  volume={104},
  number={486},
  pages={718--734},
  year={2009},
  publisher={Taylor \& Francis}
}

@article{rousseeuw1996,
  title={Algorithm AS 307: Bivariate location depth},
  author={Rousseeuw, Peter J and Ruts, Ida},
  journal={Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  volume={45},
  number={4},
  pages={516--526},
  year={1996},
  publisher={JSTOR}
}                  
                  
@inproceedings{cheng2001,
  title={On algorithms for simplicial depth.},
  author={Cheng, Andrew Y and Ouyang, Ming},
  booktitle={CCCG},
  pages={53--56},
  year={2001}
}
                  
@article{krishnan2006,
  title={Statistical data depth and the graphics hardware},
  author={Krishnan, Suresh and Mustafa, Nabil H and Venkatasubramanian, Suresh},
  journal={DIMACS Series in Discrete Mathematics and Theoretical Computer Science},
  volume={72},
  pages={223},
  year={2006},
  publisher={AMERICAN MATHEMATICAL SOCIETY}
}

@article{Zasenko2016,
  author    = {Olga Zasenko and
               Tamon Stephen},
  title     = {Algorithms for Colourful Simplicial Depth and Medians in the Plane},
  journal   = {CoRR},
  volume    = {abs/1608.07348},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.07348},
  archivePrefix = {arXiv},
  eprint    = {1608.07348},
  timestamp = {Wed, 07 Jun 2017 14:42:05 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/ZasenkoS16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}                  
                  
@article{Linderman2017,
  author    = {George C. Linderman and
               Stefan Steinerberger},
  title     = {Clustering with t-SNE, provably},
  journal   = {CoRR},
  volume    = {abs/1706.02582},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.02582},
  archivePrefix = {arXiv},
  eprint    = {1706.02582},
  timestamp = {Mon, 03 Jul 2017 13:29:02 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/LindermanS17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{wattenberg2016how,
  author = {Wattenberg, Martin and Viégas, Fernanda and Johnson, Ian},
  title = {How to Use t-SNE Effectively},
  journal = {Distill},
  year = {2016},
  url = {http://distill.pub/2016/misread-tsne},
  doi = {10.23915/distill.00002}
}

@INPROCEEDINGS{Lee_Verleysen2014, 
author={J. A. Lee and M. Verleysen}, 
booktitle={2014 IEEE Symposium on Computational Intelligence and Data Mining (CIDM)}, 
title={Two key properties of dimensionality reduction methods}, 
year={2014}, 
volume={}, 
number={}, 
pages={163-170}, 
keywords={data reduction;data structures;neural nets;principal component analysis;DR;data representation;deep neural networks;dimensionality reduction;principal component analysis;Cost function;Covariance matrices;Force;Manifolds;Plastics;Principal component analysis;Vectors}, 
doi={10.1109/CIDM.2014.7008663}, 
ISSN={}, 
month={Dec},}

@inproceedings{simon1996,
  title={Anonymous communication and anonymous cash},
  author={Simon, Daniel R},
  booktitle={Annual International Cryptology Conference},
  pages={61--73},
  year={1996},
  organization={Springer}
}
@inproceedings{al2016,
  title={Categorical Compositional Cognition},
  author={Al-Mehairi, Yaared and Coecke, Bob and Lewis, Martha},
  booktitle={International Symposium on Quantum Interaction},
  pages={122--134},
  year={2016},
  organization={Springer}
}
                  
@article{kartsaklis2013,
  title={Reasoning about meaning in natural language with compact closed categories and frobenius algebras},
  author={Kartsaklis, Dimitri and Sadrzadeh, Mehrnoosh and Pulman, Stephen and Coecke, Bob},
  journal={Logic and Algebraic Structures in Quantum Computing},
  pages={199},
  year={2013}
}
                  

@article{berger2017cite2vec,
  title={cite2vec: citation-driven document exploration via word embeddings},
  author={Berger, Matthew and McDonough, Katherine and Seversky, Lee M},
  journal={IEEE transactions on visualization and computer graphics},
  volume={23},
  number={1},
  pages={691--700},
  year={2017},
  publisher={IEEE}
}

@article{lagarias2002beyond,
  title={Beyond the Descartes circle theorem},
  author={Lagarias, Jeffrey C and Mallows, Colin L and Wilks, Allan R},
  journal={The American mathematical monthly},
  volume={109},
  number={4},
  pages={338--361},
  year={2002},
  publisher={JSTOR}
}


@article{Gatys2015,
  author    = {Leon A. Gatys and
               Alexander S. Ecker and
               Matthias Bethge},
  title     = {A Neural Algorithm of Artistic Style},
  journal   = {CoRR},
  volume    = {abs/1508.06576},
  year      = {2015},
  url       = {http://arxiv.org/abs/1508.06576},
  archivePrefix = {arXiv},
  eprint    = {1508.06576},
  timestamp = {Wed, 07 Jun 2017 14:41:58 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/GatysEB15a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Haber2017,
  author    = {Eldad Haber and
               Lars Ruthotto},
  title     = {Stable Architectures for Deep Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1705.03341},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.03341},
  archivePrefix = {arXiv},
  eprint    = {1705.03341},
  timestamp = {Wed, 07 Jun 2017 14:40:21 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HaberR17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Chang2017,
  author    = {Bo Chang and
               Lili Meng and
               Eldad Haber and
               Lars Ruthotto and
               David Begert and
               Elliot Holtham},
  title     = {Reversible Architectures for Arbitrarily Deep Residual Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1709.03698},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.03698},
  archivePrefix = {arXiv},
  eprint    = {1709.03698},
  timestamp = {Thu, 05 Oct 2017 09:42:58 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1709-03698},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Szegedy2013,
  author    = {Christian Szegedy and
               Wojciech Zaremba and
               Ilya Sutskever and
               Joan Bruna and
               Dumitru Erhan and
               Ian J. Goodfellow and
               Rob Fergus},
  title     = {Intriguing properties of neural networks},
  journal   = {CoRR},
  volume    = {abs/1312.6199},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.6199},
  archivePrefix = {arXiv},
  eprint    = {1312.6199},
  timestamp = {Wed, 07 Jun 2017 14:41:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SzegedyZSBEGF13},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
@article{Johnson2016,
  author    = {Justin Johnson and
               Alexandre Alahi and
               Fei{-}Fei Li},
  title     = {Perceptual Losses for Real-Time Style Transfer and Super-Resolution},
  journal   = {CoRR},
  volume    = {abs/1603.08155},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.08155},
  archivePrefix = {arXiv},
  eprint    = {1603.08155},
  timestamp = {Wed, 07 Jun 2017 14:40:26 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/JohnsonAL16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
                  
                  @article{prakash2018,
  author    = {Aaditya Prakash and
               Nick Moran and
               Solomon Garber and
               Antonella DiLillo and
               James A. Storer},
  title     = {Deflecting Adversarial Attacks with Pixel Deflection},
  journal   = {CoRR},
  volume    = {abs/1801.08926},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.08926},
  archivePrefix = {arXiv},
  eprint    = {1801.08926},
  timestamp = {Fri, 02 Feb 2018 14:20:25 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-08926},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{prakash_ecting_nodate,
	title = {Deflecting Adversarial Attacks with Pixel Deflection},
	abstract = {CNNs are poised to become integral parts of many critical systems. Despite their robustness to natural variations, image pixel values can be manipulated, via small, carefully crafted, imperceptible perturbations, to cause a model to misclassify images. We present an algorithm to process an image so that classiﬁcation accuracy is signiﬁcantly preserved in the presence of such adversarial manipulations. Image classiﬁers tend to be robust to natural noise, and adversarial attacks tend to be agnostic to object location. These observations motivate our strategy, which leverages model robustness to defend against adversarial perturbations by forcing the image to match natural image statistics. Our algorithm locally corrupts the image by redistributing pixel values via a process we term pixel deflection. A subsequent wavelet-based denoising operation softens this corruption, as well as some of the adversarial changes. We demonstrate experimentally that the combination of these techniques enables the effective recovery of the true class, against a variety of robust attacks. Our results compare favorably with current state-of-the-art defenses, without requiring retraining or modifying the CNN.},
	language = {en},
	author = {Prakash, Aaditya and Moran, Nick and Garber, Solomon and DiLillo, Antonella and Storer, James and University, Brandeis},
	pages = {17},
	file = {Prakash et al. - Deflecting Adversarial Attacks with Pixel Deflection.pdf:C\:\\Users\\Nexus\\Zotero\\storage\\QUNFRPBY\\Prakash et al. - Deflecting Adversarial Attacks with Pixel Deflection.pdf:application/pdf}
}

@article{haber_stable_2018,
	title = {Stable architectures for deep neural networks},
	volume = {34},
	issn = {0266-5611, 1361-6420},
	url = {http://stacks.iop.org/0266-5611/34/i=1/a=014004?key=crossref.1cc46f347b817746f33b5329460be31b},
	doi = {10.1088/1361-6420/aa9a90},
	abstract = {Deep neural networks have become invaluable tools for supervised machine learning, e.g., classiﬁcation of text or images. While often oﬀering superior results over traditional techniques and successfully expressing complicated patterns in data, deep architectures are known to be challenging to design and train such that they generalize well to new data. Important issues with deep architectures are numerical instabilities in derivative-based learning algorithms commonly called exploding or vanishing gradients. In this paper we propose new forward propagation techniques inspired by systems of Ordinary Diﬀerential Equations (ODE) that overcome this challenge and lead to well-posed learning problems for arbitrarily deep networks.},
	language = {en},
	number = {1},
	urldate = {2018-04-25},
	journal = {Inverse Problems},
	author = {Haber, Eldad and Ruthotto, Lars},
	month = jan,
	year = {2018},
	pages = {014004},
	file = {Haber and Ruthotto - 2018 - Stable architectures for deep neural networks.pdf:C\:\\Users\\Nexus\\Zotero\\storage\\VGE5DB2I\\Haber and Ruthotto - 2018 - Stable architectures for deep neural networks.pdf:application/pdf}
}

@article{gatys_neural_2016,
	title = {A {Neural} {Algorithm} of {Artistic} {Style}},
	volume = {16},
	issn = {1534-7362},
	url = {http://jov.arvojournals.org/article.aspx?doi=10.1167/16.12.326},
	doi = {10.1167/16.12.326},
	language = {en},
	number = {12},
	urldate = {2018-04-25},
	journal = {Journal of Vision},
	author = {Gatys, Leon and Ecker, Alexander and Bethge, Matthias},
	month = sep,
	year = {2016},
	pages = {326},
	file = {Gatys et al. - 2016 - A Neural Algorithm of Artistic Style.pdf:C\:\\Use'rs\\Nexus\\Zotero\\storage\\8TSSA4PG\\Gatys et al. - 2016 - A Neural Algorithm of Artistic Style.pdf:application/pdf}
}

@article{chang_reversible_2017,
	title = {Reversible Architectures for Arbitrarily Deep Residual Neural Networks}, 
	abstract = {Recently, deep residual networks have been successfully applied in many computer vision and natural language processing tasks, pushing the state-of-the-art performance with deeper and wider architectures. In this work, we interpret deep residual networks as ordinary differential equations (ODEs), which have long been studied in mathematics and physics with rich theoretical and empirical success. From this interpretation, we develop a theoretical framework on stability and reversibility of deep neural networks, and derive three reversible neural network architectures that can go arbitrarily deep in theory. The reversibility property allows a memoryefﬁcient implementation, which does not need to store the activations for most hidden layers. Together with the stability of our architectures, this enables training deeper networks using only modest computational resources. We provide both theoretical analyses and empirical results. Experimental results demonstrate the efﬁcacy of our architectures against several strong baselines on CIFAR-10, CIFAR-100 and STL-10 with superior or on-par state-of-the-art performance. Furthermore, we show our architectures yield superior results when trained using fewer training data.},
	month = {Nov},
	year = {2017},
	language = {en},
	author = {Chang, Bo and Meng, Lili and Haber, Eldad and Ruthotto, Lars and Begert, David and Holtham, Elliot},
	pages = {8},
	file = {Chang et al. - Reversible Architectures for Arbitrarily Deep Resi.pdf:C\:\\Users\\Nexus\\Zotero\\storage\\CS6F3WMH\\Chang et al. - Reversible Architectures for Arbitrarily Deep Resi.pdf:application/pdf}
}



@article{johnson_perceptual_2016,
	title = {Perceptual {Losses} for {Real}-{Time} {Style} {Transfer} and {Super}-{Resolution}},
	url = {http://arxiv.org/abs/1603.08155},
	abstract = {We consider image transformation problems, where an input image is transformed into an output image. Recent methods for such problems typically train feed-forward convolutional neural networks using a {\textbackslash}emph\{per-pixel\} loss between the output and ground-truth images. Parallel work has shown that high-quality images can be generated by defining and optimizing {\textbackslash}emph\{perceptual\} loss functions based on high-level features extracted from pretrained networks. We combine the benefits of both approaches, and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks. We show results on image style transfer, where a feed-forward network is trained to solve the optimization problem proposed by Gatys et al in real-time. Compared to the optimization-based method, our network gives similar qualitative results but is three orders of magnitude faster. We also experiment with single-image super-resolution, where replacing a per-pixel loss with a perceptual loss gives visually pleasing results.},
	urldate = {2018-04-25},
	journal = {arXiv:1603.08155 [cs]},
	author = {Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.08155},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning},
	file = {arXiv\:1603.08155 PDF:C\:\\Users\\Nexus\\Zotero\\storage\\8P957BLX\\Johnson et al. - 2016 - Perceptual Losses for Real-Time Style Transfer and.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Nexus\\Zotero\\storage\\5XBNB97T\\1603.html:text/html}
}

@article{goodfellow_explaining_2014,
	title = {Explaining and {Harnessing} {Adversarial} {Examples}},
	url = {http://arxiv.org/abs/1412.6572},
	abstract = {Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.},
	urldate = {2018-04-25},
	journal = {arXiv:1412.6572 [cs, stat]},
	author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.6572},
	keywords = {Computer Science - Learning, Statistics - Machine Learning},
	file = {arXiv\:1412.6572 PDF:C\:\\Users\\Nexus\\Zotero\\storage\\4AJ5ZRYV\\Goodfellow et al. - 2014 - Explaining and Harnessing Adversarial Examples.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Nexus\\Zotero\\storage\\KB34UKC8\\1412.html:text/html}
}

@article{kurakin_adversarial_2016,
	title = {Adversarial examples in the physical world},
	url = {http://arxiv.org/abs/1607.02533},
	abstract = {Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake. Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model. Up to now, all previous work have assumed a threat model in which the adversary can feed data directly into the machine learning classifier. This is not always the case for systems operating in the physical world, for example those which are using signals from cameras and other sensors as an input. This paper shows that even in such physical world scenarios, machine learning systems are vulnerable to adversarial examples. We demonstrate this by feeding adversarial images obtained from cell-phone camera to an ImageNet Inception classifier and measuring the classification accuracy of the system. We find that a large fraction of adversarial examples are classified incorrectly even when perceived through the camera.},
	urldate = {2018-04-25},
	journal = {arXiv:1607.02533 [cs, stat]},
	author = {Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.02533},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security, Computer Science - Learning, Statistics - Machine Learning},
	annote = {Comment: 14 pages, 6 figures. Demo available at https://youtu.be/zQ\_uMenoBCk},
	file = {arXiv\:1607.02533 PDF:C\:\\Users\\Nexus\\Zotero\\storage\\35I7YL6G\\Kurakin et al. - 2016 - Adversarial examples in the physical world.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Nexus\\Zotero\\storage\\6BVECYWQ\\1607.html:text/html}
}

@article{papernot_cleverhans_2016,
	title = {cleverhans v2.0.0: an adversarial machine learning library},
	shorttitle = {cleverhans v2.0.0},
	url = {http://arxiv.org/abs/1610.00768},
	abstract = {{\textbackslash}texttt\{cleverhans\} is a software library that provides standardized reference implementations of {\textbackslash}emph\{adversarial example\} construction techniques and {\textbackslash}emph\{adversarial training\}. The library may be used to develop more robust machine learning models and to provide standardized benchmarks of models' performance in the adversarial setting. Benchmarks constructed without a standardized implementation of adversarial example construction are not comparable to each other, because a good result may indicate a robust model or it may merely indicate a weak implementation of the adversarial example construction procedure. This technical report is structured as follows. Section{\textasciitilde}{\textbackslash}ref\{sec:introduction\} provides an overview of adversarial examples in machine learning and of the {\textbackslash}texttt\{cleverhans\} software. Section{\textasciitilde}{\textbackslash}ref\{sec:core\} presents the core functionalities of the library: namely the attacks based on adversarial examples and defenses to improve the robustness of machine learning models to these attacks. Section{\textasciitilde}{\textbackslash}ref\{sec:benchmark\} describes how to report benchmark results using the library. Section{\textasciitilde}{\textbackslash}ref\{sec:version\} describes the versioning system.},
	urldate = {2018-04-25},
	journal = {arXiv:1610.00768 [cs, stat]},
	author = {Papernot, Nicolas and Carlini, Nicholas and Goodfellow, Ian and Feinman, Reuben and Faghri, Fartash and Matyasko, Alexander and Hambardzumyan, Karen and Juang, Yi-Lin and Kurakin, Alexey and Sheatsley, Ryan and Garg, Abhibhav and Lin, Yen-Chen},
	month = oct,
	year = {2016},
	note = {arXiv: 1610.00768},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Learning, Statistics - Machine Learning},
	annote = {Comment: Technical report for https://github.com/openai/cleverhans},
	file = {arXiv\:1610.00768 PDF:C\:\\Users\\Nexus\\Zotero\\storage\\RTY5GJJN\\Papernot et al. - 2016 - cleverhans v2.0.0 an adversarial machine learning.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Nexus\\Zotero\\storage\\GZ9CJGY3\\1610.html:text/html}
}

@article{papernot_practical_2016,
	title = {Practical {Black}-{Box} {Attacks} against {Machine} {Learning}},
	url = {http://arxiv.org/abs/1602.02697},
	abstract = {Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24\% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19\% and 88.94\%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.},
	urldate = {2018-04-25},
	journal = {arXiv:1602.02697 [cs]},
	author = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z. Berkay and Swami, Ananthram},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.02697},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Learning},
	annote = {Comment: Proceedings of the 2017 ACM Asia Conference on Computer and Communications Security, Abu Dhabi, UAE},
	file = {arXiv\:1602.02697 PDF:C\:\\Users\\Nexus\\Zotero\\storage\\7E32ER7G\\Papernot et al. - 2016 - Practical Black-Box Attacks against Machine Learni.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Nexus\\Zotero\\storage\\VGUUWBMH\\1602.html:text/html}
}

@article{papernot_limitations_2015,
	title = {The {Limitations} of {Deep} {Learning} in {Adversarial} {Settings}},
	url = {http://arxiv.org/abs/1511.07528},
	abstract = {Deep learning takes advantage of large datasets and computationally efficient training algorithms to outperform other approaches at various machine learning tasks. However, imperfections in the training phase of deep neural networks make them vulnerable to adversarial samples: inputs crafted by adversaries with the intent of causing deep neural networks to misclassify. In this work, we formalize the space of adversaries against deep neural networks (DNNs) and introduce a novel class of algorithms to craft adversarial samples based on a precise understanding of the mapping between inputs and outputs of DNNs. In an application to computer vision, we show that our algorithms can reliably produce samples correctly classified by human subjects but misclassified in specific targets by a DNN with a 97\% adversarial success rate while only modifying on average 4.02\% of the input features per sample. We then evaluate the vulnerability of different sample classes to adversarial perturbations by defining a hardness measure. Finally, we describe preliminary work outlining defenses against adversarial samples by defining a predictive measure of distance between a benign input and a target classification.},
	urldate = {2018-04-25},
	journal = {arXiv:1511.07528 [cs, stat]},
	author = {Papernot, Nicolas and McDaniel, Patrick and Jha, Somesh and Fredrikson, Matt and Celik, Z. Berkay and Swami, Ananthram},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.07528},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	annote = {Comment: Accepted to the 1st IEEE European Symposium on Security \& Privacy, IEEE 2016. Saarbrucken, Germany},
	file = {arXiv\:1511.07528 PDF:C\:\\Users\\Nexus\\Zotero\\storage\\SI9WW5F6\\Papernot et al. - 2015 - The Limitations of Deep Learning in Adversarial Se.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Nexus\\Zotero\\storage\\VQ5FT6KW\\1511.html:text/html}
}

@article{moosavi-dezfooli_deepfool:_2015,
	title = {{DeepFool}: a simple and accurate method to fool deep neural networks},
	shorttitle = {{DeepFool}},
	url = {http://arxiv.org/abs/1511.04599},
	abstract = {State-of-the-art deep neural networks have achieved impressive results on many image classification tasks. However, these same architectures have been shown to be unstable to small, well sought, perturbations of the images. Despite the importance of this phenomenon, no effective methods have been proposed to accurately compute the robustness of state-of-the-art deep classifiers to such perturbations on large-scale datasets. In this paper, we fill this gap and propose the DeepFool algorithm to efficiently compute perturbations that fool deep networks, and thus reliably quantify the robustness of these classifiers. Extensive experimental results show that our approach outperforms recent methods in the task of computing adversarial perturbations and making classifiers more robust.},
	urldate = {2018-04-25},
	journal = {arXiv:1511.04599 [cs]},
	author = {Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.04599},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning},
	annote = {Comment: In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016},
	file = {arXiv\:1511.04599 PDF:C\:\\Users\\Nexus\\Zotero\\storage\\R4FMVV3B\\Moosavi-Dezfooli et al. - 2015 - DeepFool a simple and accurate method to fool dee.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Nexus\\Zotero\\storage\\KZ58SXIR\\1511.html:text/html}
}

@article{carlini_towards_2016,
	title = {Towards Evaluating the Robustness of Neural Networks},
	url = {http://arxiv.org/abs/1608.04644},
	abstract = {Neural networks provide state-of-the-art results for most machine learning tasks. Unfortunately, neural networks are vulnerable to adversarial examples: given an input \$x\$ and any target classification \$t\$, it is possible to find a new input \$x'\$ that is similar to \$x\$ but classified as \$t\$. This makes it difficult to apply neural networks in security-critical areas. Defensive distillation is a recently proposed approach that can take an arbitrary neural network, and increase its robustness, reducing the success rate of current attacks' ability to find adversarial examples from \$95{\textbackslash}\%\$ to \$0.5{\textbackslash}\%\$. In this paper, we demonstrate that defensive distillation does not significantly increase the robustness of neural networks by introducing three new attack algorithms that are successful on both distilled and undistilled neural networks with \$100{\textbackslash}\%\$ probability. Our attacks are tailored to three distance metrics used previously in the literature, and when compared to previous adversarial example generation algorithms, our attacks are often much more effective (and never worse). Furthermore, we propose using high-confidence adversarial examples in a simple transferability test we show can also be used to break defensive distillation. We hope our attacks will be used as a benchmark in future defense attempts to create neural networks that resist adversarial examples.},
	urldate = {2018-04-25},
	journal = {arXiv:1608.04644 [cs]},
	author = {Carlini, Nicholas and Wagner, David},
	month = aug,
	year = 2016,
	note = {arXiv: 1608.04644},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security},
	file = {arXiv\:1608.04644 PDF:C\:\\Users\\Nexus\\Zotero\\storage\\Q4T8UTKH\\Carlini and Wagner - 2016 - Towards Evaluating the Robustness of Neural Networ.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Nexus\\Zotero\\storage\\PQ7PVTRJ\\1608.html:text/html}
}

@article{madry_towards_2017,
	title = {Towards {Deep} {Learning} {Models} {Resistant} to {Adversarial} {Attacks}},
	url = {http://arxiv.org/abs/1706.06083},
	abstract = {Recent work has demonstrated that neural networks are vulnerable to adversarial examples, i.e., inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models.},
	urldate = {2018-04-25},
	journal = {arXiv:1706.06083 [cs, stat]},
	author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.06083},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	file = {arXiv\:1706.06083 PDF:C\:\\Users\\Nexus\\Zotero\\storage\\QL6LA2DS\\Madry et al. - 2017 - Towards Deep Learning Models Resistant to Adversar.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Nexus\\Zotero\\storage\\6YSIR8L9\\1706.html:text/html}
}

@article{su_one_2017,
	title = {One pixel attack for fooling deep neural networks},
	url = {http://arxiv.org/abs/1710.08864},
	abstract = {Recent research has revealed that the output of Deep Neural Networks (DNN) can be easily altered by adding relatively small perturbations to the input vector. In this paper, we analyze an attack in an extremely limited scenario where only one pixel can be modified. For that we propose a novel method for generating one-pixel adversarial perturbations based on differential evolution. It requires less adversarial information and can fool more types of networks. The results show that 70.97\% of the natural images can be perturbed to at least one target class by modifying just one pixel with 97.47\% confidence on average. Thus, the proposed attack explores a different take on adversarial machine learning in an extreme limited scenario, showing that current DNNs are also vulnerable to such low dimension attacks.},
	urldate = {2018-04-25},
	journal = {arXiv:1710.08864 [cs, stat]},
	author = {Su, Jiawei and Vargas, Danilo Vasconcellos and Kouichi, Sakurai},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.08864},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Statistics - Machine Learning},
	file = {arXiv\:1710.08864 PDF:C\:\\Users\\Nexus\\Zotero\\storage\\47WQZ5NK\\Su et al. - 2017 - One pixel attack for fooling deep neural networks.pdf:application/pdf}
}
                  

@Misc{aksh00,
author =   {Akshay Chawla},
title =    {{GTS}: {GNU} {Triangulated} {Surface} library},
howpublished = {https://github.com/akshaychawla/Adversarial-Examples-in-PyTorch},
year = 2017,
month = {November}
}

                  
@book{Bishop:2006:PRM:1162264,
 author = {Bishop, Christopher M.},
 title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
 year = {2006},
 isbn = {0387310738},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
} 
                  
@misc{arden2018,
	title = {Applied-{Deep}-{Learning}-with-{Keras}/{Part} 4 ({GPU}) - {Convolutional} {Neural} {Networks}.ipynb at master · ardendertat/{Applied}-{Deep}-{Learning}-with-{Keras} · {GitHub}},
	author={Arden Dertat},
	url = {https://github.com/ardendertat/Applied-Deep-Learning-with-Keras/blob/master/notebooks/Part%204%20%28GPU%29%20-%20Convolutional%20Neural%20Networks.ipynb},
	urldate = {2018-06-30},
	year = {2018}
}

@article{nair_rectified_nodate,
	title = {Rectified {Linear} {Units} {Improve} {Restricted} {Boltzmann} {Machines}},
	abstract = {Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an inﬁnite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these “Stepped Sigmoid Units” are unchanged. They can be approximated eﬃciently by noisy, rectiﬁed linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face veriﬁcation on the Labeled Faces in the Wild dataset. Unlike binary units, rectiﬁed linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.},
	language = {en},
	author = {Nair, Vinod and Hinton, Geoffrey E},
   booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
  pages={807--814},
	year = {2010},
	file = {Nair and Hinton - Rectified Linear Units Improve Restricted Boltzman.pdf:C\:\\Users\\Nexus\\Zotero\\storage\\MEQHIX28\\Nair and Hinton - Rectified Linear Units Improve Restricted Boltzman.pdf:application/pdf}
}

@misc{goodfellow2013multidigit,
    title={Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks},
    author={Ian J. Goodfellow and Yaroslav Bulatov and Julian Ibarz and Sacha Arnoud and Vinay Shet},
    year={2013},
    eprint={1312.6082},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
                  
@article{Khoury2018,
  author    = {Marc Khoury and
               Dylan Hadfield{-}Menell},
  title     = {On the Geometry of Adversarial Examples},
  journal   = {CoRR},
  volume    = {abs/1811.00525},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.00525},
  archivePrefix = {arXiv},
  eprint    = {1811.00525},
  timestamp = {Thu, 22 Nov 2018 17:58:30 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-00525},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
@article{mohammad16,
  author    = {Mohammad Rastegari and
               Vicente Ordonez and
               Joseph Redmon and
               Ali Farhadi},
  title     = {XNOR-Net: ImageNet Classification Using Binary Convolutional Neural
               Networks},
  journal   = {CoRR},
  volume    = {abs/1603.05279},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.05279},
  archivePrefix = {arXiv},
  eprint    = {1603.05279},
  timestamp = {Mon, 13 Aug 2018 16:47:22 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/RastegariORF16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
@article{inevitable2018,
  author    = {Ali Shafahi and
               W. Ronny Huang and
               Christoph Studer and
               Soheil Feizi and
               Tom Goldstein},
  title     = {Are adversarial examples inevitable?},
  journal   = {CoRR},
  volume    = {abs/1809.02104},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.02104},
  archivePrefix = {arXiv},
  eprint    = {1809.02104},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1809-02104},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
@article{tsipras2018robustness,
  title={Robustness may be at odds with accuracy},
  author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
  journal={stat},
  volume={1050},
  pages={11},
  year={2018}
}
@inproceedings{nguyen2015deep,
  title={Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},
  author={Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={427--436},
  year={2015}
}

                  




@article{simant2018,
  author    = {Simant Dube},
  title     = {High Dimensional Spaces, Deep Learning and Adversarial Examples},
  journal   = {CoRR},
  volume    = {abs/1801.00634},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.00634},
  archivePrefix = {arXiv},
  eprint    = {1801.00634},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-00634},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{erichson2019,
  author    = {N. Benjamin Erichson and
               Zhewei Yao and
               Michael W. Mahoney},
  title     = {JumpReLU: {A} Retrofit Defense Strategy for Adversarial Attacks},
  journal   = {CoRR},
  volume    = {abs/1904.03750},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.03750},
  archivePrefix = {arXiv},
  eprint    = {1904.03750},
  timestamp = {Thu, 25 Apr 2019 13:55:01 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1904-03750},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
@article{frosst2018,
  author    = {Nicholas Frosst and
               Sara Sabour and
               Geoffrey E. Hinton},
  title     = {{DARCCC:} Detecting Adversaries by Reconstruction from Class Conditional
               Capsules},
  journal   = {CoRR},
  volume    = {abs/1811.06969},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.06969},
  archivePrefix = {arXiv},
  eprint    = {1811.06969},
  timestamp = {Sun, 25 Nov 2018 18:57:12 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-06969},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

                  @article{Gatys2015,
  author    = {Leon A. Gatys and
               Alexander S. Ecker and
               Matthias Bethge},
  title     = {A Neural Algorithm of Artistic Style},
  journal   = {CoRR},
  volume    = {abs/1508.06576},
  year      = {2015},
  url       = {http://arxiv.org/abs/1508.06576},
  archivePrefix = {arXiv},
  eprint    = {1508.06576},
  timestamp = {Wed, 07 Jun 2017 14:41:58 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/GatysEB15a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  



%%%%#######%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{su_one_2017,
	title = {One pixel attack for fooling deep neural networks},
	url = {http://arxiv.org/abs/1710.08864},
	abstract = {Recent research has revealed that the output of Deep Neural Networks (DNN) can be easily altered by adding relatively small perturbations to the input vector. In this paper, we analyze an attack in an extremely limited scenario where only one pixel can be modified. For that we propose a novel method for generating one-pixel adversarial perturbations based on differential evolution. It requires less adversarial information and can fool more types of networks. The results show that 70.97\% of the natural images can be perturbed to at least one target class by modifying just one pixel with 97.47\% confidence on average. Thus, the proposed attack explores a different take on adversarial machine learning in an extreme limited scenario, showing that current DNNs are also vulnerable to such low dimension attacks.},
	urldate = {2018-04-25},
	journal = {arXiv:1710.08864 [cs, stat]},
	author = {Su, Jiawei and Vargas, Danilo Vasconcellos and Kouichi, Sakurai},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.08864},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Statistics - Machine Learning},
	file = {arXiv\:1710.08864 PDF:/home/bwbell/Zotero/storage/47WQZ5NK/Su et al. - 2017 - One pixel attack for fooling deep neural networks.pdf:application/pdf;arXiv.org Snapshot:/home/bwbell/Zotero/storage/LQJ8R82B/1710.html:text/html}
}

@article{madry_towards_2017,
	title = {Towards {Deep} {Learning} {Models} {Resistant} to {Adversarial} {Attacks}},
	url = {http://arxiv.org/abs/1706.06083},
	abstract = {Recent work has demonstrated that neural networks are vulnerable to adversarial examples, i.e., inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models.},
	urldate = {2018-04-25},
	journal = {arXiv:1706.06083 [cs, stat]},
	author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.06083},
	keywords = {Computer Science - Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv\:1706.06083 PDF:/home/bwbell/Zotero/storage/QL6LA2DS/Madry et al. - 2017 - Towards Deep Learning Models Resistant to Adversar.pdf:application/pdf;arXiv.org Snapshot:/home/bwbell/Zotero/storage/6YSIR8L9/1706.html:text/html}
}





@article{papernot_practical_2016,
	title = {Practical {Black}-{Box} {Attacks} against {Machine} {Learning}},
	url = {http://arxiv.org/abs/1602.02697},
	abstract = {Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24\% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19\% and 88.94\%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.},
	urldate = {2018-04-25},
	journal = {arXiv:1602.02697 [cs]},
	author = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z. Berkay and Swami, Ananthram},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.02697},
	keywords = {Computer Science - Learning, Computer Science - Cryptography and Security},
	annote = {Comment: Proceedings of the 2017 ACM Asia Conference on Computer and Communications Security, Abu Dhabi, UAE},
	file = {arXiv\:1602.02697 PDF:/home/bwbell/Zotero/storage/7E32ER7G/Papernot et al. - 2016 - Practical Black-Box Attacks against Machine Learni.pdf:application/pdf;arXiv.org Snapshot:/home/bwbell/Zotero/storage/VGUUWBMH/1602.html:text/html}
}

@article{papernot_cleverhans_2016,
	title = {cleverhans v2.0.0: an adversarial machine learning library},
	shorttitle = {cleverhans v2.0.0},
	url = {http://arxiv.org/abs/1610.00768},
	abstract = {{\textbackslash}texttt\{cleverhans\} is a software library that provides standardized reference implementations of {\textbackslash}emph\{adversarial example\} construction techniques and {\textbackslash}emph\{adversarial training\}. The library may be used to develop more robust machine learning models and to provide standardized benchmarks of models' performance in the adversarial setting. Benchmarks constructed without a standardized implementation of adversarial example construction are not comparable to each other, because a good result may indicate a robust model or it may merely indicate a weak implementation of the adversarial example construction procedure. This technical report is structured as follows. Section{\textasciitilde}{\textbackslash}ref\{sec:introduction\} provides an overview of adversarial examples in machine learning and of the {\textbackslash}texttt\{cleverhans\} software. Section{\textasciitilde}{\textbackslash}ref\{sec:core\} presents the core functionalities of the library: namely the attacks based on adversarial examples and defenses to improve the robustness of machine learning models to these attacks. Section{\textasciitilde}{\textbackslash}ref\{sec:benchmark\} describes how to report benchmark results using the library. Section{\textasciitilde}{\textbackslash}ref\{sec:version\} describes the versioning system.},
	urldate = {2018-04-25},
	journal = {arXiv:1610.00768 [cs, stat]},
	author = {Papernot, Nicolas and Carlini, Nicholas and Goodfellow, Ian and Feinman, Reuben and Faghri, Fartash and Matyasko, Alexander and Hambardzumyan, Karen and Juang, Yi-Lin and Kurakin, Alexey and Sheatsley, Ryan and Garg, Abhibhav and Lin, Yen-Chen},
	month = oct,
	year = {2016},
	note = {arXiv: 1610.00768},
	keywords = {Computer Science - Learning, Statistics - Machine Learning, Computer Science - Cryptography and Security},
	annote = {Comment: Technical report for https://github.com/openai/cleverhans},
	file = {arXiv\:1610.00768 PDF:/home/bwbell/Zotero/storage/RTY5GJJN/Papernot et al. - 2016 - cleverhans v2.0.0 an adversarial machine learning.pdf:application/pdf;arXiv.org Snapshot:/home/bwbell/Zotero/storage/GZ9CJGY3/1610.html:text/html}
}






@article{Haber2018,
	title = {Stable architectures for deep neural networks},
	volume = {34},
	issn = {0266-5611, 1361-6420},
	url = {http://stacks.iop.org/0266-5611/34/i=1/a=014004?key=crossref.1cc46f347b817746f33b5329460be31b},
	doi = {10.1088/1361-6420/aa9a90},
	abstract = {Deep neural networks have become invaluable tools for supervised machine learning, e.g., classiï¬cation of text or images. While often oï¬€ering superior results over traditional techniques and successfully expressing complicated patterns in data, deep architectures are known to be challenging to design and train such that they generalize well to new data. Important issues with deep architectures are numerical instabilities in derivative-based learning algorithms commonly called exploding or vanishing gradients. In this paper we propose new forward propagation techniques inspired by systems of Ordinary Diï¬€erential Equations (ODE) that overcome this challenge and lead to well-posed learning problems for arbitrarily deep networks.},
	language = {en},
	number = {1},
	urldate = {2018-04-25},
	journal = {Inverse Problems},
	author = {Haber, Eldad and Ruthotto, Lars},
	month = jan,
	year = {2018},
	pages = {014004},
	file = {Haber and Ruthotto - 2018 - Stable architectures for deep neural networks.pdf:/home/bwbell/Zotero/storage/VGE5DB2I/Haber and Ruthotto - 2018 - Stable architectures for deep neural networks.pdf:application/pdf}
}







@article{volodmymyr2016,
  author    = {Volodymyr Mnih and
               Adri{\`{a}} Puigdom{\`{e}}nech Badia and
               Mehdi Mirza and
               Alex Graves and
               Timothy P. Lillicrap and
               Tim Harley and
               David Silver and
               Koray Kavukcuoglu},
  title     = {Asynchronous Methods for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1602.01783},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.01783},
  archivePrefix = {arXiv},
  eprint    = {1602.01783},
  timestamp = {Wed, 07 Jun 2017 14:43:09 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MnihBMGLHSK16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
                  
@article{Johnson2016,
  author    = {Justin Johnson and
               Alexandre Alahi and
               Fei{-}Fei Li},
  title     = {Perceptual Losses for Real-Time Style Transfer and Super-Resolution},
  journal   = {CoRR},
  volume    = {abs/1603.08155},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.08155},
  archivePrefix = {arXiv},
  eprint    = {1603.08155},
  timestamp = {Wed, 07 Jun 2017 14:40:26 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/JohnsonAL16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
@article{Penghang2018,
  author    = {Penghang Yin and
               Shuai Zhang and
               Jiancheng Lyu and
               Stanley Osher and
               Yingyong Qi and
               Jack Xin},
  title     = {Blended Coarse Gradient Descent for Full Quantization of Deep Neural
               Networks},
  journal   = {CoRR},
  volume    = {abs/1808.05240},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.05240},
  archivePrefix = {arXiv},
  eprint    = {1808.05240},
  timestamp = {Fri, 21 Dec 2018 14:34:10 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1808-05240},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

                  
@inproceedings{selvaraju2017,
	address = {Venice},
	title = {Grad-{CAM}: {Visual} {Explanations} from {Deep} {Networks} via {Gradient}-{Based} {Localization}},
	isbn = {978-1-5386-1032-9},
	shorttitle = {Grad-{CAM}},
	url = {http://ieeexplore.ieee.org/document/8237336/},
	doi = {10.1109/ICCV.2017.74},
	abstract = {We propose a technique for producing â€˜visual explanationsâ€™ for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent. Our approach â€“ Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say logits for â€˜dogâ€™ or even a caption), ï¬‚owing into the ï¬nal convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, Grad-CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g. VGG), (2) CNNs used for structured outputs (e.g. captioning), (3) CNNs used in tasks with multi-modal inputs (e.g. VQA) or reinforcement learning, without architectural changes or re-training. We combine Grad-CAM with existing ï¬ne-grained visualizations to create a high-resolution class-discriminative visualization and apply it to image classiï¬cation, image captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classiï¬cation models, our visualizations (a) lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) are robust to adversarial images, (c) outperform previous methods on the ILSVRC-15 weakly-supervised localization task, (d) are more faithful to the underlying model, and (e) help achieve model generalization by identifying dataset bias. For image captioning and VQA, our visualizations show even non-attention based models can localize inputs. Finally, we design and conduct human studies to measure if Grad-CAM explanations help users establish appropriate trust in predictions from deep networks and show that GradCAM helps untrained users successfully discern a â€˜strongerâ€™ deep network from a â€˜weakerâ€™ one. Our code is available at https://github.com/ramprs/grad-cam/ and a demo is available on CloudCV [2]1. Video of the demo can be found at youtu.be/COjUB9Izk6E.},
	language = {en},
	urldate = {2019-05-16},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	month = oct,
	year = {2017},
	pages = {618--626},
	file = {Selvaraju et al. - 2017 - Grad-CAM Visual Explanations from Deep Networks v.pdf:/home/bwbell/Zotero/storage/G7359QEK/Selvaraju et al. - 2017 - Grad-CAM Visual Explanations from Deep Networks v.pdf:application/pdf}
}
                  






                  
@inproceedings{Lee2018ASU,
  title={A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks},
  author={Kimin Lee and Kibok Lee and Honglak Lee and Jinwoo Shin},
  booktitle={NeurIPS},
  year={2018}
}

@inproceedings{gao2018robust,
  title={Robust hypothesis testing using wasserstein uncertainty sets},
  author={Gao, Rui and Xie, Liyan and Xie, Yao and Xu, Huan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7902--7912},
  year={2018}
}

@inproceedings{Zhou:2010:IYR:1879141.1879193,
 author = {Zhou, Renjie and Khemmarat, Samamon and Gao, Lixin},
 title = {The Impact of YouTube Recommendation System on Video Views},
 booktitle = {Proceedings of the 10th ACM SIGCOMM Conference on Internet Measurement},
 series = {IMC '10},
 year = {2010},
 isbn = {978-1-4503-0483-2},
 location = {Melbourne, Australia},
 pages = {404--410},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/1879141.1879193},
 doi = {10.1145/1879141.1879193},
 acmid = {1879193},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {YouTube, recommendation system, video sharing site, view diversity, view sources},
} 

@article{DBLP:journals/corr/abs-1811-10104,
  author    = {Ben Hutchinson and
               Margaret Mitchell},
  title     = {50 Years of Test (Un)fairness: Lessons for Machine Learning},
  journal   = {CoRR},
  volume    = {abs/1811.10104},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.10104},
  archivePrefix = {arXiv},
  eprint    = {1811.10104},
  timestamp = {Fri, 30 Nov 2018 12:44:28 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-10104},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/EvtimovEFKLPRS17,
  author    = {Ivan Evtimov and
               Kevin Eykholt and
               Earlence Fernandes and
               Tadayoshi Kohno and
               Bo Li and
               Atul Prakash and
               Amir Rahmati and
               Dawn Song},
  title     = {Robust Physical-World Attacks on Machine Learning Models},
  journal   = {CoRR},
  volume    = {abs/1707.08945},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.08945},
  archivePrefix = {arXiv},
  eprint    = {1707.08945},
  timestamp = {Thu, 09 May 2019 13:10:56 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/EvtimovEFKLPRS17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
@article{DBLP:journals/corr/BojarskiTDFFGJM16,
  author    = {Mariusz Bojarski and
               Davide Del Testa and
               Daniel Dworakowski and
               Bernhard Firner and
               Beat Flepp and
               Prasoon Goyal and
               Lawrence D. Jackel and
               Mathew Monfort and
               Urs Muller and
               Jiakai Zhang and
               Xin Zhang and
               Jake Zhao and
               Karol Zieba},
  title     = {End to End Learning for Self-Driving Cars},
  journal   = {CoRR},
  volume    = {abs/1604.07316},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.07316},
  archivePrefix = {arXiv},
  eprint    = {1604.07316},
  timestamp = {Mon, 13 Aug 2018 16:47:06 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/BojarskiTDFFGJM16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
                  
@article{wyly2008subprime,
  title={Subprime mortgage segmentation in the American urban system},
  author={Wyly, Elvin K and Moos, Markus and Foxcroft, Holly and Kabahizi, Emmanuel},
  journal={Tijdschrift voor economische en sociale geografie},
  volume={99},
  number={1},
  pages={3--23},
  year={2008},
  publisher={Wiley Online Library}
}
                  
@article{rosenblatt1958perceptron,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Rosenblatt, Frank},
  journal={Psychological review},
  volume={65},
  number={6},
  pages={386},
  year={1958},
  publisher={American Psychological Association}
}


                  
@book{ivakhnenko1965cybernetic,
  title={Cybernetic predicting devices},
  author={Ivakhnenko, Alekse Grigorevich and Lapa, Valentin Grigor\'evich},
  year={1965},
  publisher={CCM Information Corporation}
}

@article{SCHMIDHUBER201585,
title = "Deep learning in neural networks: An overview",
journal = "Neural Networks",
volume = "61",
pages = "85 - 117",
year = "2015",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2014.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0893608014002135",
author = "JÃ¼rgen Schmidhuber",
keywords = "Deep learning, Supervised learning, Unsupervised learning, Reinforcement learning, Evolutionary computation",
abstract = "In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks."
}

@article{minsky1969perceptrons,
  title={Perceptrons: Anlntroduction to computational geometry},
  author={Minsky, Marvin and Papert, Seymour},
  journal={MITPress, Cambridge, Massachusetts},
  year={1969}
}

@article{werbos1974beyond,
  title={Beyond regression: New tools for prediction and analysis in the be havioral sciences/'PhD diss., Harvard Uni versity. Werbos, Paul J. 1988},
  author={Werbos, Paul J},
  journal={Generalization of back propagation with application to a recurrent gas market method," Neural Networks},
  volume={1},
  number={4},
  pages={339--356},
  year={1974}
}

@article{mcclelland1986parallel,
  title={Parallel distributed processing},
  author={McClelland, James L and Rumelhart, David E and PDP Research Group and others},
  journal={Explorations in the Microstructure of Cognition},
  volume={2},
  pages={216--271},
  year={1986},
  publisher={MIT Press Cambridge, Ma}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick and others},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Taipei, Taiwan}
}

@article{lecun1989backpropagation,
  title={Backpropagation applied to handwritten zip code recognition},
  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal={Neural computation},
  volume={1},
  number={4},
  pages={541--551},
  year={1989},
  publisher={MIT Press}
}

@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year=2014
}

@article{malik1990preattentive,
  title={Preattentive texture discrimination with early vision mechanisms},
  author={Malik, Jitendra and Perona, Pietro},
  journal={JOSA A},
  volume={7},
  number={5},
  pages={923--932},
  year={1990},
  publisher={Optical Society of America}
}

@inproceedings{li2017convergence,
	title="Convergence Analysis of Two-layer Neural Networks with ReLU Activation",
	author="Yuanzhi {Li} and Yang {Yuan}",
	booktitle="Advances in Neural Information Processing Systems",
	pages="597--607",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2963519230",
	year="2017"
}
@article{petersen2018optimal,
  title={Optimal approximation of piecewise smooth functions using deep ReLU neural networks},
  author={Petersen, Philipp and Voigtlaender, Felix},
  journal={Neural Networks},
  volume={108},
  pages={296--330},
  year={2018},
  publisher={Elsevier}
}

@article{HardtRS15,
  author    = {Moritz Hardt and
               Benjamin Recht and
               Yoram Singer},
  title     = {Train faster, generalize better: Stability of stochastic gradient
               descent},
  journal   = {CoRR},
  volume    = {abs/1509.01240},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.01240},
  archivePrefix = {arXiv},
  eprint    = {1509.01240},
  timestamp = {Mon, 13 Aug 2018 16:46:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HardtRS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{liu2015very,
  title={Very deep convolutional neural network based image classification using small training sample size},
  author={Liu, Shuying and Deng, Weihong},
  booktitle={2015 3rd IAPR Asian conference on pattern recognition (ACPR)},
  pages={730--734},
  year={2015},
  organization={IEEE}
}
@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group}
}
@inproceedings{lecun1988theoretical,
  title={A theoretical framework for back-propagation},
  author={LeCun, Yann and Touresky, D and Hinton, G and Sejnowski, T},
  booktitle={Proceedings of the 1988 connectionist models summer school},
  volume={1},
  pages={21--28},
  year={1988},
  organization={CMU, Pittsburgh, Pa: Morgan Kaufmann}
}

@article{liu1989limited,
  title={On the limited memory BFGS method for large scale optimization},
  author={Liu, Dong C and Nocedal, Jorge},
  journal={Mathematical programming},
  volume={45},
  number={1-3},
  pages={503--528},
  year={1989},
  publisher={Springer}
}

@article{lecun1995convolutional,
  title={Convolutional networks for images, speech, and time series},
  author={LeCun, Yann and Bengio, Yoshua and others},
  journal={The handbook of brain theory and neural networks},
  volume={3361},
  number={10},
  pages={1995},
  year={1995}
}

@article{mcculloch1943logical,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S and Pitts, Walter},
  journal={The bulletin of mathematical biophysics},
  volume={5},
  number={4},
  pages={115--133},
  year={1943},
  publisher={Springer}
}

@article{linnainmaa1970representation,
  title={The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors},
  author={Linnainmaa, Seppo},
  journal={Master's Thesis (in Finnish), Univ. Helsinki},
  pages={6--7},
  year={1970}
}

@article{kak1993training,
  title={On training feedforward neural networks},
  author={Kak, Subhash},
  journal={Pramana},
  volume={40},
  number={1},
  pages={35--42},
  year={1993},
  publisher={Springer}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{wiyatno2018saliency,
  author    = {Rey Wiyatno and
               Anqi Xu},
  title     = {Maximal Jacobian-based Saliency Map Attack},
  journal   = {CoRR},
  volume    = {abs/1808.07945},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.07945},
  archivePrefix = {arXiv},
  eprint    = {1808.07945},
  timestamp = {Sun, 02 Sep 2018 15:01:56 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-07945.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{Krause20,
  author        = {Andreas Krause},
  title         = {Introduction to Machine Learning},
  month         = {August},
  year          = {2020},
  publisher={Learning and Adaptive Systems ETH}
}

@inproceedings{coates2011analysis,
  title={An analysis of single-layer networks in unsupervised feature learning},
  author={Coates, Adam and Ng, Andrew and Lee, Honglak},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={215--223},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}
@inproceedings{glorot2011deep,
  title={Deep sparse rectifier neural networks},
  author={Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={315--323},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}
@article{collobert2011natural,
  title={Natural language processing (almost) from scratch},
  author={Collobert, Ronan and Weston, Jason and Bottou, L{\'e}on and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
  journal={Journal of machine learning research},
  volume={12},
  number={ARTICLE},
  pages={2493--2537},
  year={2011}
}
@inproceedings{mikolov2010recurrent,
  title={Recurrent neural network based language model.},
  author={Mikolov, Tomas and Karafi{\'a}t, Martin and Burget, Lukas and Cernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  volume={2},
  number={3},
  pages={1045--1048},
  year={2010},
  organization={Makuhari}
}
@article{vincent2010stacked,
  title={Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion.},
  author={Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine and Bottou, L{\'e}on},
  journal={Journal of machine learning research},
  volume={11},
  number={12},
  year={2010}
}
@inproceedings{boureau2010learning,
  title={Learning mid-level features for recognition},
  author={Boureau, Y-Lan and Bach, Francis and LeCun, Yann and Ponce, Jean},
  booktitle={2010 IEEE computer society conference on computer vision and pattern recognition},
  pages={2559--2566},
  year={2010},
  organization={IEEE}
}
@article{hinton2010practical,
  title={A practical guide to training restricted Boltzmann machines},
  author={Hinton, Geoffrey},
  journal={Momentum},
  volume={9},
  number={1},
  pages={926},
  year={2010}
}
@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}
@inproceedings{erhan2010does,
  title={Why does unsupervised pre-training help deep learning?},
  author={Erhan, Dumitru and Courville, Aaron and Bengio, Yoshua and Vincent, Pascal},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={201--208},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}
@article{bengio2009learning,
  title={Learning deep architectures for AI},
  author={Bengio, Yoshua and others},
  journal={Foundations and trends{\textregistered} in Machine Learning},
  volume={2},
  number={1},
  pages={1--127},
  year={2009},
  publisher={Now Publishers, Inc.}
}
@inproceedings{lee2009convolutional,
  title={Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations},
  author={Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={609--616},
  year={2009}
}
@misc{bengio2007greedy,
  title={Greedy layer-wise training of deep networks. NIPS 19 (pp. 153--160)},
  author={Bengio, Y and Lamblin, P and Popovici, D and Larochelle, H},
  year={2007},
  publisher={MIT Press}
}
@article{hinton2006reducing,
  title={Reducing the dimensionality of data with neural networks},
  author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  journal={science},
  volume={313},
  number={5786},
  pages={504--507},
  year={2006},
  publisher={American Association for the Advancement of Science}
}
@article{hinton2006fast,
  title={A fast learning algorithm for deep belief nets},
  author={Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
  journal={Neural computation},
  volume={18},
  number={7},
  pages={1527--1554},
  year={2006},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

and an inexorable expansion of  pre-built and well-maintained
libraries for working with neural networks including the two most
famous: torch 2002 and tensorflow (released 2015)

@inproceedings{Collobert2002TorchAM,
  title={Torch: a modular machine learning software library},
  author={Ronan Collobert and Samy Bengio and Johnny Mari{\'e}thoz},
  year={2002}
}
@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}
@misc{tensorflow2015-whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}
 @misc{vaswani2017attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
